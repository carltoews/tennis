{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: center\"> Predicting Professional Tennis Match Outcomes</p>\n",
    "\n",
    "**Author:**  Carl Toews  \n",
    "**Date: ** August 8, 2017  \n",
    "\n",
    "**Project Description:**  This project explores various machine learning techniques on professional tennis data.  The data set was compiled by Jeff Sackman (https://github.com/JeffSackmann/tennis_atp) and consists of the Association of Tennis Professionals (ATP) match outcomes for all major ATP matches since 1968.  In all there are over half a million records.  Features change slightly over the years, but by 2017 include almost 50 elements, including rank, age, seed, and match statistics for both the winner and loser. \n",
    "\n",
    "**Technical specs:** I've tested this notebook on Python 3.6.2 and MySQL 5.7.16.\n",
    "\n",
    "\n",
    "**Outline:**    \n",
    "I. <a href=\"#mysql\"> MySQL database setup</a>   \n",
    "II.  <a href=\"#logisticregression_1d\"> One-dimensional logistic regression demo:  predicting with rank differences </a>  \n",
    "III.  <a href=\"#logisticregression_nd\"> $n$-dimensional logistic regression demo:  predicting with other features </a>  \n",
    "III.  <a href=\"#svm\"> SVM demo:  age and height difference    </a>  \n",
    "IV.  <a href=\"#todos\"> TODOs </a> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I:  <a name=\"mysql\"> MySQL database setup</a>  \n",
    "\n",
    "The data on Sackman's page is in CSV format.  While it's easy enough to read such data directly into a pandas data structure, one of my goals in this project is to get some practice with the Pandas-MySQL interface.  To set the stage for this work, I first need to transfer all the data from CSV files to a MySQL database.  Since this process is involved, I have included it in a separate notebook called [setup_mysql_database](./setup_mysql_database.ipynb).  \n",
    "\n",
    "If the data is already in a MySQL database, skip this notebook, but if it is not, or you are not sure, run it.  It will first check to see whether the CSV data has already been put into a MySQL database, and if it has not, it will create such a database. In order to run the notebook, you will need the username and password of a MySQL user that has permission to create databases and tables. \n",
    "\n",
    "Once the MySQL database is in place, you can run the following cells, which establish the connectivity needed to execute the remainder of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure parameters\n",
    "\n",
    "Adjust as necessary to accomodate different paths, directories, and usernames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# name of database\n",
    "db_name = \"tennis\"\n",
    "# name of db user\n",
    "username = \"testuser\"\n",
    "# db password for db user\n",
    "password = \"test623\"\n",
    "# location of atp data files\n",
    "atpfile_directory = \"./data/tennis_atp-master/\"\n",
    "# location of odds data files\n",
    "oddsfiles_directory = \"./data/odds_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages\n",
    "\n",
    "All import statements related to connectivity and error analysis are here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlalchemy # pandas-mysql interface library\n",
    "import sqlalchemy.exc # exception handling\n",
    "from   sqlalchemy import create_engine  # needed to define db interface\n",
    "import sys # for defining behavior under errors\n",
    "from IPython.core.debugger import Tracer\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish database connection\n",
    "\n",
    "Try to connect to the `tennis` database on the local mysql host.  If successful,  print out the MySQL version number, if unsuccessful, exit gracefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database version : \n",
      "('5.7.16',)\n"
     ]
    }
   ],
   "source": [
    "# create an engine for interacting with the MySQL database\n",
    "try:\n",
    "    eng_str = 'mysql+mysqldb://' + username + ':' + password + '@localhost/' + db_name\n",
    "    engine = create_engine(eng_str)\n",
    "    connection = engine.connect()\n",
    "    version = connection.execute(\"SELECT VERSION()\")\n",
    "    print(\"Database version : \")\n",
    "    print(version.fetchone())\n",
    "    \n",
    "# report what went wrong if this fails.    \n",
    "except sqlalchemy.exc.DatabaseError as e:\n",
    "    reason = e.message\n",
    "    print(\"Error %s:\" % (reason))\n",
    "    sys.exit(1)\n",
    "\n",
    "# close the connection\n",
    "finally:            \n",
    "    if connection:    \n",
    "        connection.close()\n",
    "    else:\n",
    "        print(\"Failed to create connection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.  <a name=\"logisticregression_1d\"> One-dimensional Logistic regression:  rank as predictor</a>  \n",
    "\n",
    "We start out by performing logistic regression on rank alone, with the aim of seeing to what extent rank difference can be used as predictive tool.  The development is similar to the one here:\n",
    "\n",
    "1.  *Clarke and Kyte, \"Using official ratings to simulate major tennis tournaments\", International Transactions in Operational Research, 2000.*\n",
    "\n",
    "Our work flow will involve SQL queries, pandas data frames, and numpy arrays, more or less as follows:\n",
    "1.  use SQL query to extract data and store it in a pandas data frame\n",
    "2.  use the pandas data frame to manipulate data and extract features\n",
    "3.  extract preprocessed data into a numpy array for computational work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements\n",
    "\n",
    "We will need some scientific computing libraries (`scipy`), some data handling libraries (`pandas`), and some plotting functionality (`matplotlib`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # numerical libraries\n",
    "import scipy as sp\n",
    "import pandas as pd # for data analysis\n",
    "import pandas.io.sql as sql # for interfacing with MySQL database\n",
    "from scipy import linalg # linear algebra libraries\n",
    "from scipy import optimize\n",
    "import matplotlib as mpl # a big library with plotting functionality\n",
    "import matplotlib.pyplot as plt # a subset of matplotlib with most of the useful tools\n",
    "import IPython as IP\n",
    "%matplotlib inline \n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction\n",
    "\n",
    "We'll focus on data since 2011, since that is the data for which I have information on the betting markets.  The MySQL query avoids any match for which one or another of the players has no rank points. We extract winner rank points and loser rank points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract from MySQL database info on rank points and height for both winner and loser, store in dataframe\n",
    "with engine.begin() as connection:\n",
    "    rawdata = pd.read_sql_query(\"\"\"SELECT winner_rank_points, loser_rank_points FROM matches \\\n",
    "                            WHERE tourney_date < '20150101' \\\n",
    "                            AND tourney_date > '20110101'\n",
    "                            AND winner_rank_points IS NOT NULL \\\n",
    "                            AND loser_rank_points IS NOT NULL\"\"\", connection)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "\n",
    "If the winner had a higher rank than the loser, the 'rank prediction' was considered a 'success', otherwise it is a 'failure'.  For analysis, we store only the absolute value of the rank difference, along with the outcome of the match.  We also scale the data for numerical well-behavedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# winner rank minus loser rank\n",
    "rank_diff = (rawdata['winner_rank_points'] - rawdata['loser_rank_points']).values\n",
    "# index variable:  True if higher ranked player won, False otherwise\n",
    "y = (rank_diff > 0)\n",
    "# final dataset with two cols: difference in rankings, high ranked height minus low ranked height  \n",
    "X = np.abs(rank_diff)\n",
    "# for numerical well-behavedness, we need to scale and center the data\n",
    "#X1=(X-np.mean(X,0))/np.std(X,axis=0)\n",
    "X=X/np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions\n",
    "\n",
    "To perform the regression, we'll need to define the **sigmoid function** and a **cost function.**  The former can take a scalar, vector, or matrix, and return the elementwise value of\n",
    "\n",
    "$$\n",
    "\\frac{1}{1+e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "    Usage:  sigmoid(z)\n",
    "    \n",
    "    Description:  Computes value of sigmoid function for scalar.  \n",
    "    For vector or matrix, computes values of sigmoid function for each entry.\n",
    "    '''\n",
    "\n",
    "    return 1/(1+np.exp(-z));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is designed to take a regularization parameter lambda.  For a non-regularized solution, lambda can be set equal to 0.  The cost function returns both a cost and the gradient for any given value of parameters $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a cost function\n",
    "def costFunction(theta,X,y,lam,offset=True):\n",
    "    '''\n",
    "    Computes the cost and gradient for logistic regression.\n",
    "    \n",
    "    Input: \n",
    "           theta (mx1 numpy array of parameters)\n",
    "           X (nxm numpy array of feature values, first column all 1s)\n",
    "           y (nx1 boolean array of outcomes, 1=higher ranked player won, 0 otherwise)\n",
    "           lam (scalar:  regularization paramter)\n",
    "           offset (bool:  True of first element of theta represents a translation, False otherwise)\n",
    "           \n",
    "    Output:  \n",
    "           cost (scalar value of cost)\n",
    "    '''\n",
    "\n",
    "    # number of data points\n",
    "    n = len(y) \n",
    "    #number of parameters\n",
    "    m = len(theta)   \n",
    " \n",
    "    # make sure vectors are column vectors for use of \"np.dot\"\n",
    "    theta = theta.reshape(-1,1)\n",
    "    y = y.reshape(-1,1)\n",
    "    X = X.reshape(-1,1) if m==1 else X\n",
    "    \n",
    "    # input to sigmoid function will be a column vector\n",
    "    z = np.dot(X,theta) if len(theta) > 1 else X*theta\n",
    "    \n",
    "    # cost function\n",
    "    regterms = np.arange(1,m) if offset else np.arange(0,m)\n",
    "    #Tracer()() \n",
    "    J = (1/n)*(-np.dot(y.transpose(),np.log(sigmoid(z))) - \\\n",
    "                     np.dot((1-y.transpose()),np.log(1-sigmoid(z))) + \\\n",
    "                    (lam/(2))*np.sum(theta[regterms]**2))\n",
    "  \n",
    "    # gradient\n",
    "    #Tracer()()\n",
    "    reggrad = np.insert(theta[regterms],0,0)\n",
    "    grad = (1/n)*np.sum((sigmoid(z) - y)*X,0) + (lam/n)*reggrad\n",
    "    \n",
    "    \n",
    "    return np.squeeze(J), np.squeeze(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small test:  make sure the cost function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that cost function works\n",
    "theta = np.array([1.0])\n",
    "lam = 0\n",
    "cost, grad = costFunction(theta, X, y*1,lam)\n",
    "print(\"cost:\", cost)\n",
    "print(\"grad:\", grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For diagnostic purposes, we define a `callback` function that will print information about the state and gradient as the optimization algorithm proceeds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def callbackF(theta):\n",
    "    global NFeval\n",
    "    global X\n",
    "    global y\n",
    "    global lam\n",
    "    cost,grad = costFunction(theta,X,y*1,lam)\n",
    "    print(\"%4d   %3.6f  %3.6f  %3.6f\" % \\\n",
    "          (NFeval, theta, cost, grad)) \n",
    "    NFeval+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize\n",
    "\n",
    "Finally, we perform the logistic regression using scipy's built-in `optimization.minimize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFeval = 1\n",
    "initial_theta = np.array([.1])\n",
    "print(\"iter      theta     cost      grad  \")\n",
    "res = sp.optimize.minimize(lambda t:  costFunction(t,X,y*1,lam), initial_theta, method='CG',\\\n",
    "                           jac=True,options={'maxiter':100,'disp':True},callback=callbackF)                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram empirical success probabilities by \n",
    "hist, bin_edges = np.histogram(X,bins=100)\n",
    "p = [np.sum(y[np.where((X>=bin_edges[i]) & (X<bin_edges[i+1]))[0]])/hist[i] for i in np.arange(len(bin_edges)-1)]\n",
    "bar_pos = np.arange(len(p))\n",
    "bar_width = np.diff(bin_edges)\n",
    "plt.bar(bin_edges[0:-1], p, width=bar_width, align='edge', alpha=0.5)\n",
    "r = np.arange(X.min(),X.max(),.1)\n",
    "#s = 1/(1+np.exp(-res.x*r))\n",
    "s = 1/(1+np.exp(-res.x*r))\n",
    "plt.plot(r,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare predictions to those from the betting odds\n",
    "\n",
    "We'll evaluate the success of our methods by comparing our predictions to those implied by the betting markets.  In order to do this, we need to establish a 1-1 correspondence between matches in the `odds` database and matches in the `matches` database.  \n",
    "\n",
    "**Data wrangling**\n",
    "\n",
    "Matching is not straightforward, unfortunately.   The `odds` data contains the variables `Location` and `Tournament`, while the `matches` data contains `tourney_name`.  But the names are not consistent across these datasets:  for example, the tournament \"French Open\" in `odds` is called \"Roland Garros\" in `matches`.  The `Location` variable in `odds` is generally a pretty close match to the `tourney_name` in `matches`, but not always.  Moreoever, the `date` variables differ slightly between these datasets:  sometimes, every match in a tournament is pegged with a single date (generally the start date), sometimes each match has the date it was actually played.  \n",
    "\n",
    "The following code attempt to work through these and related issues.  There is a fair bit of ugly data wrangling involved:  my solution is ultimately to build a lookup table connecting `Location` in `odds` to `tourney_name` in matches.  The part of the table where there is an actual match between these variables is easy to build; the other part involves some manual inspection of the underlying CSV files.  The code builds the easy part of the table, and then flags which matches still need to be identified manually.  I focus on data in the 2010-2016 range.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds = pd.read_pickle('./data/pickle_files/odds.pkl')\n",
    "matches=pd.read_pickle('./data/pickle_files/matches.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from the appropriate timefame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two-dimension problem:  Rank + Height**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract from MySQL database info on rank points and height for both winner and loser, store in dataframe\n",
    "with engine.begin() as connection:\n",
    "    rawdata = pd.read_sql_query(\"\"\"SELECT winner_rank_points, loser_rank_points, winner_ht, loser_ht FROM matches \\\n",
    "                            WHERE tourney_date < '20150101' \\\n",
    "                            AND tourney_date > '20110101'\n",
    "                            AND winner_rank_points IS NOT NULL \\\n",
    "                            AND loser_rank_points IS NOT NULL \\\n",
    "                            AND winner_ht IS NOT NULL \\\n",
    "                            AND loser_ht IS NOT NULL\"\"\", connection)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# winner rank minus loser rank\n",
    "rank_diff = (rawdata['winner_rank_points'] - rawdata['loser_rank_points']).values\n",
    "# winner height minus loser height\n",
    "ht_diff = (rawdata['winner_ht']-rawdata['loser_ht']).values\n",
    "# index variable:  True if higher ranked player won, False otherwise\n",
    "y = (rank_diff > 0)\n",
    "# higher ranked height minus lower ranked height\n",
    "rank_ht_diff = np.where(y==True, ht_diff,-ht_diff)\n",
    "# final dataset with two cols: difference in rankings, high ranked height minus low ranked height  \n",
    "X = np.column_stack([np.abs(rank_diff), rank_ht_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for numerical well-behavedness, we need to scale and center the data\n",
    "X=(X-np.mean(X,axis=0))/np.std(X,axis=0)\n",
    "# prepend column of 1s to X\n",
    "X=np.insert(X,0,1,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance the numbers of correct and incorrect predictions via oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of \"True\" minus the number of \"False\"\n",
    "nsamps = sum(y) - sum(~y)\n",
    "# the smaller class can be associated with either \"True\" or \"False\"\n",
    "smallclass = bool(nsamps<0)\n",
    "# sample with replacement from data of the appropriate class\n",
    "samps = X[np.random.choice(np.where(y==smallclass)[0],size=nsamps),:]\n",
    "# augment the old data\n",
    "X1 = np.concatenate((X,samps),axis=0)\n",
    "y1 = np.concatenate((y,np.zeros(nsamps,dtype=bool)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the normalized data\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(X1[y1,1],X1[y1,2],\"ro\")\n",
    "ax.plot(X1[~y1,1],X1[~y1,2],\"bo\")\n",
    "ax.set_xlabel('Rank difference')\n",
    "ax.set_ylabel('Height')\n",
    "ax.set_title('Higher-rank-wins as a function of rank difference and height')\n",
    "ax.legend(['High rank wins','Low rank wins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the regression, we'll need to define the sigmoid function and a cost function.  The former can take a scalar, vector, or matrix, and return the elementwise value of\n",
    "\n",
    "$$\n",
    "\\frac{1}{1+e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "    Usage:  sigmoid(z)\n",
    "    \n",
    "    Description:  Computes value of sigmoid function for scalar.  \n",
    "    For vector or matrix, computes values of sigmoid function for each entry.\n",
    "    '''\n",
    "\n",
    "    return 1/(1+np.exp(-z));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is designed to take a regularization parameter lambda.  For a non-regularized solution, lambda can be set equal to 0.  The cost function returns both a cost and the gradient for any given value of parameters $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a cost function\n",
    "def costFunction(theta,X,y,lam):\n",
    "    '''\n",
    "    Computes the cost and gradient for logistic regression.\n",
    "    \n",
    "    Input: \n",
    "           theta (3x1 vector of parameters)\n",
    "           X (nx3 matrix of feature values, first column all 1s)\n",
    "           y (nx1 binary vector of outcomes, 1=higher ranked player won, 0 otherwise)\n",
    "           lam (scalar:  regularization paramter)\n",
    "           \n",
    "    Output:  \n",
    "           cost (scalar value of cost)\n",
    "    '''\n",
    "\n",
    "    # number of data points\n",
    "    m = len(y) \n",
    "    # make sure vectors are column vectors\n",
    "    theta = theta.reshape(-1,1)\n",
    "    y = y.reshape(-1,1)\n",
    "    \n",
    "    # input to sigmoid function will be a column vector\n",
    "    z = np.dot(X,theta)\n",
    "    \n",
    "    # cost function\n",
    "    J = (1/m)*np.sum(np.dot(-y.transpose(),np.log(sigmoid(z))) - \\\n",
    "                     np.dot((1-y.transpose()),np.log(1-sigmoid(z)))) + \\\n",
    "                    (lam/(2*m))*np.sum(theta[1:len(theta)+1]**2);\n",
    "  \n",
    "    # gradient\n",
    "    regterm = np.insert(theta[1:len(theta)+1],0,0)\n",
    "    grad = (1/m)*np.sum((sigmoid(z) - y)*X,0) + (lam/m)*regterm\n",
    "    \n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small test:  make sure the cost function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check that cost function works\n",
    "theta = np.array([1,2,3])\n",
    "lam = 0\n",
    "cost, grad = costFunction(theta, X1, y1*1,lam)\n",
    "print(\"cost:\", cost)\n",
    "print(\"grad:\", grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For diagnostic purposes, we define a `callback` function that will print information about the state and gradient as the optimization algorithm proceeds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def callbackF(theta):\n",
    "    global NFeval\n",
    "    global X1\n",
    "    global y1\n",
    "    global lam\n",
    "    cost,grad = costFunction(theta,X1,y1*1,lam)\n",
    "    print(\"%4d   %3.6f   %3.6f   %3.6f   %3.6f   %3.6f  %3.6f  %3.6f\" % \\\n",
    "          (NFeval, theta[0], theta[1], theta[2], cost, grad[0], grad[1], grad[2]))  \n",
    "    NFeval+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run optimization\n",
    "NFeval = 1\n",
    "#initial_theta = np.array([-5,4,3])\n",
    "initial_theta = np.array([1])\n",
    "#print(\"iter      t1          t2         t3     cost      grad1       grad2       grad3\")\n",
    "#res = sp.optimize.minimize(lambda t:  costFunction(t,X1,y1*1,lam), initial_theta, method='CG',\\\n",
    "#                           jac=True,options={'maxiter':100,'disp':True}, callback=callbackF)   \n",
    "res = sp.optimize.minimize(lambda t:  costFunction(t,X1,y1*1,lam), initial_theta, method='CG',\\\n",
    "                           jac=True,options={'maxiter':100,'disp':True})                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how it did, we replot the data with the logistic classifier superimposed over the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the normalized data with regression line\n",
    "theta = res.x\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(X1[y1,1],X1[y1,2],\"ro\",markerfacecolor=\"None\")\n",
    "ax.plot(X1[~y1,1],X1[~y1,2],\"bo\",markerfacecolor=\"None\")\n",
    "xplot = np.array([-3,3])\n",
    "yplot = (-1/theta[2])*(theta[1]*xplot+theta[0])\n",
    "ax.plot(xplot,yplot,'g',linewidth=2)\n",
    "ax.set_xlabel('Rank difference')\n",
    "ax.set_ylabel('Height')\n",
    "ax.set_title('Higher-rank-wins as a function of age and height')\n",
    "ax.set_ylim((-5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also develop a quantitative measure of success:  count the number of correct predictions, and compare to what would have been predicted by rank alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_success_rate = np.sum(y)/len(y)\n",
    "y_pred = (np.dot(X,theta)>0)\n",
    "prediction_success_rate = np.sum(~(y^y_pred))/len(y)\n",
    "print(\"prediction success rate: \", prediction_success_rate)\n",
    "print(\"rank success rate: \", rank_success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try to duplicate the above with sklearn's canned logistic algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=1., solver='lbfgs')\n",
    "t = lr.fit(X1,y1*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=lr.decision_function(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "The above procedure turns tennis match outcomes into training data by assigning 1s to matches in which the higher ranked opponent won.  \n",
    "\n",
    "TODO: \n",
    "\n",
    "1.  investigate other methods of classifying matches as 1s or 0s\n",
    "2.  investigate other combinations of features to use for the regression\n",
    "3.  test feature choices by dividing data set into training, validation, and test sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.  <a name=\"svm\"> SVM Demo </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section uses some basic `scikit` functionality to train an SVM classifier on rank and ace data. The example is again a trivial one, but defines a workflow and sets the stage for investigating more complex relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll use the SVM package in the scikit library\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After classifying the SVM classifier, we'll need some helper functions to form contour plots. These helper functions are borrowed from the `scikit` documentation, http://scikit-learn.org/stable/auto_examples/svm/plot_iris.html#sphx-glr-auto-examples-svm-plot-iris-py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# produce a dense grid of points in rectangle around the data\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "# produce a contour plot with predicted outcomes from SVM classifier\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run our test on a slightly different set of data than last time.  Here, we'll still classify matches as `1` if the higher ranked player wins and `0` otherwise, but we'll focus on age and height as our predictive features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract from MySQL database info on rank points and height for both winner and loser, store in dataframe\n",
    "with engine.begin() as connection:\n",
    "    rawdata = pd.read_sql_query(\"\"\"SELECT winner_rank_points, loser_rank_points, winner_age, loser_age, winner_ht, loser_ht \\\n",
    "                            FROM matches \\\n",
    "                            WHERE tourney_date > '20170101' \\\n",
    "                            AND winner_rank_points IS NOT NULL \\\n",
    "                            AND loser_rank_points IS NOT NULL \\\n",
    "                            AND winner_age IS NOT NULL \\\n",
    "                            AND loser_age IS NOT NULL \\\n",
    "                            AND winner_ht IS NOT NULL \\\n",
    "                            AND loser_ht IS NOT NULL\"\"\", connection)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary connecting `matches` tourney_name to `odds` Location\n",
    "tourney_pairs =  \\\n",
    "[('Brisbane','Brisbane')  ,\n",
    "('Chennai','Chennai')  ,\n",
    "('Doha','Doha')  ,\n",
    "('Auckland','Auckland')  ,\n",
    "('Sydney','Sydney')  ,\n",
    "('Australian Open','Melbourne')  ,\n",
    "('Johannesburg','Johannesburg')  ,\n",
    "('Santiago','Santiago')  ,\n",
    "('Zagreb','Zagreb')  ,\n",
    "('Costa Do Sauipe','Costa Do Sauipe')  ,\n",
    "('Rotterdam','Rotterdam')  ,\n",
    "('San Jose','San Jose')  ,\n",
    "('Buenos Aires','Buenos Aires')  ,\n",
    "('Marseille','Marseille')  ,\n",
    "('Memphis','Memphis')  ,\n",
    "('Acapulco','Acapulco')  ,\n",
    "('Delray Beach','Delray Beach')  ,\n",
    "('Dubai','Dubai')  ,\n",
    "('Indian Wells Masters','Indian Wells')  ,\n",
    "('Miami Masters','Miami')  ,\n",
    "('Casablanca','Casablanca')  ,\n",
    "('Houston','Houston')  ,\n",
    "('Monte Carlo Masters','Monte Carlo')  ,\n",
    "('Barcelona','Barcelona')  ,\n",
    "('Rome Masters','Rome')  ,\n",
    "('Belgrade','Belgrade')  ,\n",
    "('Munich','Munich')  ,\n",
    "('Estoril','Estoril')  ,\n",
    "('Madrid Masters', 'Madrid')  ,\n",
    "('Roland Garros','Paris')  ,\n",
    "('Nice','Nice')  ,\n",
    "(\"Queen's Club\",'Queens Club')  ,\n",
    "('Halle','Halle')  ,\n",
    "('s-Hertogenbosch',\"'s-Hertogenbosch\")  ,\n",
    "('Eastbourne','Eastbourne')  ,\n",
    "('Wimbledon','London')  ,\n",
    "('Newport','Newport')  ,\n",
    "('Stuttgart','Stuttgart')  ,\n",
    "('Bastad','Bastad')  ,\n",
    "('Hamburg','Hamburg')  ,\n",
    "('Atlanta','Atlanta')  ,\n",
    "('Los Angeles','Los Angeles')  ,\n",
    "('Gstaad', 'Gstaad')  ,\n",
    "('Washington','Washington')  ,\n",
    "('Umag', 'Umag')  ,\n",
    "('Canada Masters','Toronto')  ,\n",
    "('Canada Masters','Montreal')  ,\n",
    "('Cincinnati Masters','Cincinnati')  ,\n",
    "('US Open','New York')  ,\n",
    "('Metz','Metz')  ,\n",
    "('Bucharest','Bucharest')  ,\n",
    "('Kuala Lumpur','Kuala Lumpur')  ,\n",
    "('Bangkok', 'Bangkok')  ,\n",
    "('Tokyo','Tokyo')  ,\n",
    "('Beijing', 'Beijing')  ,\n",
    "('Moscow','Moscow')  ,\n",
    "('Shanghai Masters','Shanghai')  ,\n",
    "('Montpellier','Montpellier')  ,\n",
    "('Stockholm','Stockholm')  ,\n",
    "('Vienna','Vienna')  ,\n",
    "('St. Petersburg', 'St. Petersburg')  ,\n",
    "('Basel','Basel')  ,\n",
    "('Valencia','Valencia')  ,\n",
    "('Paris Masters','Paris')  ,\n",
    "('Tour Finals','London'),\n",
    "('New Haven', 'New Haven'),\n",
    "('Kitzbuhel','Kitzbuhel'),\n",
    "('Winston-Salem','Winston-Salem'),\n",
    "('Sao Paulo','Sao Paulo'),\n",
    "('Bogota','Bogota'),\n",
    "('Vina del Mar','Vina del Mar'),\n",
    "('Santiago','Vina del Mar'),\n",
    "('Estoril','Oeiras'),\n",
    "('Power Horse Cup','Dusseldorf'),\n",
    "('Rio de Janeiro','Rio de Janeiro'),\n",
    "('Dusseldorf','Dusseldorf'),\n",
    "('Shenzhen','Shenzhen'),\n",
    "('Quito','Quito'),\n",
    "('Istanbul','Istanbul'),\n",
    "('Geneva','Geneva'),\n",
    "('London','Queens Club'),\n",
    "('Nottingham','Nottingham'),\n",
    "('Sofia','Sofia'),\n",
    "('Marrakech','Marrakech'),\n",
    "('Los Cabos','Los Cabos'),\n",
    "('Us Open','New York'),\n",
    "('St.Petersburg','St. Petersburg'),\n",
    "('Chengdu','Chengdu'),\n",
    "('Antwerp','Antwerp'),\n",
    "('London','London')]\n",
    "\n",
    "# use dictionary keys and values as columns in a dataframe\n",
    "tourney_lookup = pd.DataFrame(tourney_pairs,columns = ['m_name','o_name'])\n",
    "tourney_lookup.m_name = tourney_lookup.m_name.str.lower().str.strip()\n",
    "tourney_lookup.o_name = tourney_lookup.o_name.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this nx2 array contains the differences in ages and the differences in height\n",
    "X = pd.concat([rawdata.iloc[:,2]-rawdata.iloc[:,3], \\\n",
    "               rawdata.iloc[:,4]-rawdata.iloc[:,5]], axis=1).values\n",
    "\n",
    "# this nx1 binary array indicates whether the match was a \"success\" or a \"failure\", as predicted by ranking differences\n",
    "y = (rawdata.iloc[:,0]-rawdata.iloc[:,1]).values > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for numerical well-behavedness, we need to scale and center the data\n",
    "X=(X-np.mean(X,axis=0))/np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the normalized data \n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(X[y,0],X[y,1],\"ro\")\n",
    "ax.plot(X[~y,0],X[~y,1],\"bo\")\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Height')\n",
    "ax.set_title('Higher-rank-wins as a function of age and height')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll  use the `scikit` svm package to train an SVM classifier on this data.  We'll plot the results as a contour graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the SVM classifier\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y) \n",
    "\n",
    "# generate a dense grid for producing a contour plot\n",
    "X0, X1 = X[:, 0], X[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "# feed the grid into the plot_contours routinge\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plot_contours(ax, clf, xx, yy,\n",
    "              cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xlabel('Rank points')\n",
    "ax.set_ylabel('First serve %')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title('SVM classifier for height/age data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these features produce a fairly mixed set of points, so they are unlikely to be highly predictive.  But it is interesting to note the pocket of blue in the lower left corner:  it suggests that, all other being equal, players who are younger and shorter are likely to fair worse than predicted.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.  Betting\n",
    "\n",
    "Here we explore the profitability of our algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# name of database\n",
    "db_name = \"tennis\"\n",
    "# name of db user\n",
    "username = \"testuser\"\n",
    "# db password for db user\n",
    "password = \"test623\"\n",
    "# location of atp data files\n",
    "atpfile_directory = \"../data/tennis_atp-master/\"\n",
    "# location of odds data files\n",
    "oddsfiles_directory = \"../data/odds_data/\"\n",
    "\n",
    "#%%\n",
    "\n",
    "#\n",
    "# PACKAGES\n",
    "#\n",
    "\n",
    "import sqlalchemy # pandas-mysql interface library\n",
    "import sqlalchemy.exc # exception handling\n",
    "from   sqlalchemy import create_engine  # needed to define db interface\n",
    "import glob # for file manipulation\n",
    "import sys # for defining behavior under errors\n",
    "\n",
    "#%%\n",
    "\n",
    "#\n",
    "# This cell tries to connect to the mysql database \"db_name\" with the login\n",
    "# info supplied above.  If it succeeds, it prints out the version number of \n",
    "# mysql, if it fails, it exits gracefully.\n",
    "#\n",
    "\n",
    "# create an engine for interacting with the MySQL database\n",
    "try:\n",
    "    eng_str = 'mysql+mysqldb://' + username + ':' + password + '@localhost/' + db_name\n",
    "    engine = create_engine(eng_str)\n",
    "    connection = engine.connect()\n",
    "    version = connection.execute(\"SELECT VERSION()\")\n",
    "    print(\"Database version : \")\n",
    "    print(version.fetchone())\n",
    "\n",
    "# report what went wrong if this fails.    \n",
    "except sqlalchemy.exc.DatabaseError as e:\n",
    "    reason = e.message\n",
    "    print(\"Error %s:\" % (reason))\n",
    "    sys.exit(1)\n",
    "\n",
    "# close the connection\n",
    "finally:            \n",
    "    if connection:    \n",
    "        connection.close()\n",
    "    else:\n",
    "        print(\"Failed to create connection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract from MySQL database info odds\n",
    "with engine.begin() as connection:\n",
    "    rawdata = pd.read_sql_query(\"\"\"SELECT PSW, PSL, WRank, LRank FROM odds \\\n",
    "                            WHERE PSW IS NOT NULL \\\n",
    "                            AND PSL IS NOT NULL \\\n",
    "                            AND WRank IS NOT NULL \\\n",
    "                            AND LRank IS NOT NULL;\"\"\", connection)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "investment = len(rawdata)\n",
    "good_call_idx = (rawdata[\"LRank\"]-rawdata[\"WRank\"]>0)\n",
    "winner_odds = rawdata[\"PSW\"]\n",
    "gain = sum(winner_odds*good_call_idx) \n",
    "roi = gain - investment\n",
    "\n",
    "print(\"total invested:  \", investment)\n",
    "print(\"return on investment:  \", roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.min(winner_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.  <a name=\"todos\"> TODOs </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is just the begining part of this analysis.  The gold standard for professional tennis match prediction is to beat the betting market.  There is odds data available for many of these matches, and the proper metric for predictive success is probably percentage increase in profit.\n",
    "\n",
    "Further work includes the following:\n",
    "\n",
    "1.  implement a neural net\n",
    "2.  systematically investigate other combinations of features, including polynomial features\n",
    "3.  use `join` commands to extract more complex subsets of the data (i.e. court-type specific data, players of a certain origin, players with certain tournament play patterns, etc.)\n",
    "4.  benchmark algorithms against one another using expected winnings ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=10\n",
    "X = np.random.normal(0,1,(n,2))\n",
    "y = np.random.choice(a=[False, True], size=n)\n",
    "X1= np.insert(X,0,1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n0=100\n",
    "n1=100\n",
    "m0 = 0\n",
    "m1 = 0\n",
    "s0 = 1\n",
    "s1 = 1\n",
    "X = np.concatenate((np.random.normal(m0,s0,(n0,2)), \\\n",
    "                    np.concatenate((np.random.normal(0,s1,size=(n1,1)), \\\n",
    "                                    np.random.normal(m1,s1,size=(n1,1))),axis=1)),axis=0)\n",
    "X1 = np.insert(X,0,1,axis=1)\n",
    "y = np.concatenate((np.ones((n0),dtype=bool),np.zeros((n1),dtype=bool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    rawdata = pd.read_sql_query(\"\"\"SELECT DISTINCT tourney_date, winner_name, winner_rank_points, winner_rank, \\\n",
    "                            loser_name, loser_rank_points, loser_rank FROM matches \\\n",
    "                            WHERE tourney_date > '20150101' \\\n",
    "                            AND tourney_date < '20160101' \\\n",
    "                            AND tourney_name = \"Wimbledon\"; \"\"\", connection)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    rawdata = pd.read_sql_query(\"\"\"SELECT odds.Date, matches.tourney_date, odds.Tournament, \\\n",
    "                            SUBSTRING(odds.winner,1,LOCATE(' ',odds.winner)) AS 'Winner', \\\n",
    "                            SUBSTRING(odds.loser,1,LOCATE(' ',odds.loser)) AS 'Loser', \\\n",
    "                            odds.PSW, odds.PSL, \\\n",
    "                            matches.winner_rank_points, matches.loser_rank_points \\\n",
    "                            FROM odds \\\n",
    "                            INNER JOIN matches \\\n",
    "                            ON odds.Date = matches.tourney_date \\\n",
    "                            AND odds.Tournament = matches.tourney_name \\\n",
    "                            AND odds.Tournament = \"Wimbledon\" \\\n",
    "                            AND odds.Date > '20150101' \\\n",
    "                            ; \"\"\", connection)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    rawdata = pd.read_sql_query(\"\"\"SELECT odds.Date, matches.tourney_date, odds.Tournament, \\\n",
    "                            SUBSTRING(odds.winner,1,LOCATE(' ',odds.winner)), \\\n",
    "                            SUBSTRING(odds.loser,1,LOCATE(' ',odds.loser)) \\\n",
    "                            FROM odds \\\n",
    "                            INNER JOIN matches \\\n",
    "                            ON (odds.Date = matches.tourney_date \\\n",
    "                            AND odds.Tournament = matches.tourney_name \\\n",
    "                            AND odds.Tournament = \"Wimbledon\" \\\n",
    "                            AND matches.winner_name REGEXP SUBSTRING(odds.winner,1,LOCATE(' ',odds.winner)) \\\n",
    "                            AND matches.loser_name REGEXP SUBSTRING(odds.loser,1,LOCATE(' ',odds.loser))) \\\n",
    "                            ; \"\"\", connection)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    rawdata = pd.read_sql_query(\"\"\"SELECT (matches.winner_name REGEXP SUBSTRING(odds.winner,1,LOCATE(' ',odds.winner))) AS 'Namematch', \\\n",
    "                            SUBSTRING(odds.winner,1,LOCATE(' ',odds.winner)) AS 'Winner', \\\n",
    "                            SUBSTRING(odds.loser,1,LOCATE(' ',odds.loser)) AS 'Loser', \\\n",
    "                            matches.winner_name, matches.loser_name \\\n",
    "                            FROM matches \\\n",
    "                            INNER JOIN odds \\\n",
    "                            ON (odds.Tournament=\"Wimbledon\" AND \\\n",
    "                            odds.Winner = \"Tomic B.\") \\\n",
    "                            ; \"\"\", connection)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an engine for interacting with the MySQL database\n",
    "db_name = \"test\"\n",
    "try:\n",
    "    engine.execute(\"CREATE DATABASE IF NOT EXISTS \" + db_name) #create db\n",
    "    engine.execute(\"USE \" + db_name) # select new db\n",
    "\n",
    "    # report what went wrong if this fails.    \n",
    "except sqlalchemy.exc.DatabaseError as e:\n",
    "    reason = e.message\n",
    "    print(\"Error %s:\" % (reason))\n",
    "    sys.exit(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "        connection.execute(\"CREATE TABLE matches (tourney_name VARCHAR(256));\")\n",
    "        connection.execute(\"ALTER TABLE matches ADD COLUMN tourney_date DATE;\")\n",
    "        connection.execute(\"ALTER TABLE matches ADD COLUMN winner_name VARCHAR(256);\")\n",
    "        connection.execute(\"ALTER TABLE matches ADD COLUMN winner_rank_points SMALLINT UNSIGNED;\")\n",
    "        connection.execute(\"ALTER TABLE matches ADD COLUMN loser_name VARCHAR(256);\") \n",
    "        connection.execute(\"ALTER TABLE matches ADD COLUMN loser_rank_points SMALLINT UNSIGNED;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "        query=(\"\"\"CREATE TABLE odds \n",
    "        (Tournament\tVARCHAR(256),\n",
    "         Date DATE,\n",
    "         Winner VARCHAR(256), \n",
    "         Loser VARCHAR(256), \n",
    "         PSW DECIMAL(5,3),\n",
    "         PSL DECIMAL(5,3))\n",
    "         ;\"\"\")\n",
    "        connection.execute(query) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "        query=(\"\"\"CREATE TABLE t1 \n",
    "        (name VARCHAR(256),\n",
    "         id tinyint unsigned)\n",
    "         ;\"\"\")\n",
    "        connection.execute(query) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "        query=(\"\"\"CREATE TABLE t2 \n",
    "        (name VARCHAR(256),\n",
    "         id tinyint unsigned)\n",
    "         ;\"\"\")\n",
    "        connection.execute(query) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    connection.execute(\"\"\"insert into t1 (name, id) values \\\n",
    "    (\"Bob the Blob\", 3), \\\n",
    "    (\"Pedro el Gato\", 4), \\\n",
    "    (\"Josie Slatterly\", 5), \\\n",
    "    (\"Urs Burs\", 4);\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    connection.execute(\"\"\"insert into t2 (name, id) values \\\n",
    "    (\"Blob B.\", 3), \\\n",
    "    (\"Gato P.\", 5), \\\n",
    "    (\"Slatterly J.\", 5), \\\n",
    "    (\"Burs U.\", 3);\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    rawdata = pd.read_sql_query(\"\"\"SELECT t1.name, t1.id, t2.name, t2.id, \\\n",
    "                            SUBSTRING(t2.name,1,LOCATE(' ',t2.name)) \\\n",
    "                            FROM t1 \\\n",
    "                            JOIN t2 \\\n",
    "                            ON (t1.name REGEXP SUBSTRING(t2.name,1,LOCATE(' ',t2.name))) \\\n",
    "                            ; \"\"\", connection)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    connection.execute(\"\"\"insert into matches values ('Wimbledon', '20150629', \\\n",
    "    'Jarkko Nieminen', 564, 'Lleyton Hewitt', 118);\"\"\")\n",
    "    connection.execute(\"\"\"insert into matches values ('Wimbledon', '20150629', \\\n",
    "    'Pierre Hugues Herbert', 353, 'Hyeon Chung', 79);\"\"\")\n",
    "    connection.execute(\"\"\"insert into matches values ('Wimbledon', '20160629', \\\n",
    "    'Bernard Tomic', 1355, 'Jan Lennard Struff', 112);\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    connection.execute(\"\"\"insert into odds values ('Wimbledon', '20150629', \\\n",
    "    'Przysiezny M.','Ljubicic I.', 4.880, 1.230);\"\"\")\n",
    "    connection.execute(\"\"\"insert into odds values ('Wimbledon', '20150629', \\\n",
    "    'Lopez F.','Levine J.', 1.270, 4.300);\"\"\")\n",
    "    connection.execute(\"\"\"insert into odds values ('Wimbledon', '2016-06-21', \\\n",
    "    'Lu Y.H.','Zeballos H.', 1.910, 2.020);\"\"\")\n",
    "    connection.execute(\"\"\"insert into odds values ('Wimbledon', '20160629', \\\n",
    "    'Tomic B.','Struff J.L.', 1.910, 2.020);\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    connection.execute(\"\"\"CREATE VIEW odds_names AS (    \n",
    "    SELECT \\\n",
    "    SUBSTRING(t2.name,1,LOCATE(' ',t2.name)) AS 'Name' \\\n",
    "    FROM t2\n",
    "    );\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    connection.execute(\"\"\"select * from t1 inner join on (t1.name regexp odds_names.Name)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<!--bibtex\n",
    "\n",
    "@Article{PER-GRA:2007,\n",
    "  Author    = {P\\'erez, Fernando and Granger, Brian E.},\n",
    "  Title     = {{IP}ython: a System for Interactive Scientific Computing},\n",
    "  Journal   = {Computing in Science and Engineering},\n",
    "  Volume    = {9},\n",
    "  Number    = {3},\n",
    "  Pages     = {21--29},\n",
    "  month     = may,\n",
    "  year      = 2007,\n",
    "  url       = \"http://ipython.org\",\n",
    "  ISSN      = \"1521-9615\",\n",
    "  doi       = {10.1109/MCSE.2007.53},\n",
    "  publisher = {IEEE Computer Society},\n",
    "}\n",
    "\n",
    "@article{Papa2007,\n",
    "  author = {Papa, David A. and Markov, Igor L.},\n",
    "  journal = {Approximation algorithms and metaheuristics},\n",
    "  pages = {1--38},\n",
    "  title = {{Hypergraph partitioning and clustering}},\n",
    "  url = {http://www.podload.org/pubs/book/part\\_survey.pdf},\n",
    "  year = {2007}\n",
    "}\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--bibtex\n",
    "\n",
    "@Article{PER-GRA:2007,\n",
    "  Author    = {P\\'erez, Fernando and Granger, Brian E.},\n",
    "  Title     = {{IP}ython: a System for Interactive Scientific Computing},\n",
    "  Journal   = {Computing in Science and Engineering},\n",
    "  Volume    = {9},\n",
    "  Number    = {3},\n",
    "  Pages     = {21--29},\n",
    "  month     = may,\n",
    "  year      = 2007,\n",
    "  url       = \"http://ipython.org\",\n",
    "  ISSN      = \"1521-9615\",\n",
    "  doi       = {10.1109/MCSE.2007.53},\n",
    "  publisher = {IEEE Computer Society},\n",
    "}\n",
    "\n",
    "@article{Papa2007,\n",
    "  author = {Papa, David A. and Markov, Igor L.},\n",
    "  journal = {Approximation algorithms and metaheuristics},\n",
    "  pages = {1--38},\n",
    "  title = {{Hypergraph partitioning and clustering}},\n",
    "  url = {http://www.podload.org/pubs/book/part\\_survey.pdf},\n",
    "  year = {2007}\n",
    "}\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bibliography:**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of \"True\" minus the number of \"False\"\n",
    "nsamps = sum(y) - sum(~y)\n",
    "# the smaller class can be associated with either \"True\" or \"False\"\n",
    "smallclass = bool(nsamps<0)\n",
    "# sample with replacement from data of the appropriate class\n",
    "samps = X1[np.random.choice(np.where(y==smallclass)[0],size=nsamps)]\n",
    "# augment the old data\n",
    "X1 = np.concatenate((X,samps),axis=0)\n",
    "y1 = np.concatenate((y,np.zeros(nsamps,dtype=bool)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.display(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "startdate = '20100101'\n",
    "enddate = '20171231'\n",
    "with engine.begin() as connection:\n",
    "    matchdata = pd.read_sql_query(\"\"\"SELECT tourney_date AS Date, tourney_name AS Tournament, \\\n",
    "                            winner_id AS WID, winner_name AS WName, winner_rank_points AS WPts, \\\n",
    "                            loser_id AS LID, loser_name AS LName, loser_rank_points AS LPts \\\n",
    "                            FROM matches \\\n",
    "                            WHERE tourney_date < '\"\"\" + enddate + \"\"\"' \\\n",
    "                            AND tourney_date > '\"\"\" + startdate + \"\"\"'  \\\n",
    "                            AND tourney_level = 'G' \\\n",
    "                            AND winner_rank_points IS NOT NULL \\\n",
    "                            AND loser_rank_points IS NOT NULL\n",
    "                            ;\"\"\", connection)\n",
    "    \n",
    "    oddsdata = pd.read_sql_query(\"\"\"SELECT Date, Tournament, \\\n",
    "                            Winner, WPts, Loser, LPts, \\\n",
    "                            PSW, PSL\n",
    "                            FROM odds \\\n",
    "                            WHERE Date < '\"\"\" + enddate + \"\"\"' \\\n",
    "                            AND Date > '\"\"\" + startdate + \"\"\"' \\\n",
    "                            AND Series = 'Grand Slam' \\\n",
    "                            ;\"\"\", connection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
